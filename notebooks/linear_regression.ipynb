{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest possible machine learning example: linear regression\n",
    "\n",
    "We use linear regression i.e. adjusting a straight line to a set of data points as an example of how we can gradually learn the parameters for a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (technical detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = numpy.array(range(1,11))\n",
    "y = numpy.array([2.5, 3, 6.5, 7.3, 6.9, 7.3, 10.3, 9.9, 10.3, 12.5])\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supposed relationship between input and output\n",
    "\n",
    "From the plot above, it seems reasonable to believe that there is a linear relationship between x values (input) and y values (output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(k, m):\n",
    "    return k + m*X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We'd like to find out the best values for k and m. This can be done algebraically, but for demonstration purposes we'll do it using machine learning techniques.\n",
    "\n",
    "We'll use mean squared error as our cost function and optimize using batch gradient descent.\n",
    "\n",
    "The model training setup looks like this:\n",
    "\n",
    "![Model training setup](linear_regression.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01 # learning rate\n",
    "\n",
    "def plot_current_state(k, m, cost_history):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.xlabel(\"X\", fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(\"y\", fontsize=20, fontweight='bold')\n",
    "    plt.plot(X, line(k, m), 'r-')\n",
    "    plt.plot(X, y, 'bo')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.xlim(0, 10)\n",
    "    plt.xlabel(\"iteration\", fontsize=20, fontweight='bold')\n",
    "    plt.ylabel(\"cost\", fontsize=20, fontweight='bold')\n",
    "    plt.plot(range(len(cost_history)), cost_history, 'rx-', markersize=12, linewidth=1)\n",
    "    plt.show()\n",
    "\n",
    "def mean_squared_error(predicted_y, actual_y):\n",
    "    errors = numpy.subtract(predicted_y, actual_y)\n",
    "    squared_errors = numpy.multiply(errors, errors)\n",
    "    return 0.5 * (1/len(errors)) * numpy.sum(squared_errors) \n",
    "\n",
    "def update_parameters_with_gradient_descent(k, m):\n",
    "    errors = numpy.subtract(line(k, m), y)\n",
    "    k = k - alpha * (1/len(X)) * numpy.sum(errors)\n",
    "    m = m - alpha * (1/len(X)) * numpy.sum(numpy.multiply(errors, X))\n",
    "    return (k, m)\n",
    "\n",
    "def training_iteration(k, m, cost_history):\n",
    "    (k, m) = update_parameters_with_gradient_descent(k, m)\n",
    "    current_cost = mean_squared_error(line(k, m), y)\n",
    "    \n",
    "    cost_history.append(current_cost)\n",
    "    plot_current_state(k, m, cost_history)\n",
    "    \n",
    "    return (k, m, cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "m = 0\n",
    "cost = mean_squared_error(line(k, m), y)\n",
    "\n",
    "cost_history = [] # this is just to be able to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(k, m, cost_history) = training_iteration(k, m, cost_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
