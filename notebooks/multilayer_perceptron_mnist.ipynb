{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network to Recognize Handwritten Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Stage\n",
    "\n",
    "### Importing Useful Libraries\n",
    "\n",
    "We start by importing some useful libraries: numpy for matrices, keras for machine learning and mathplotlib for visualizing data. We also make mathplotlib plots appear 'inline' i.e. in the notebook, along with the rest of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training and Validation Data\n",
    "\n",
    "Download MNIST dataset (if needed) and separate training data and validation data. 'X' matrices are input data and 'y' vectors are actual outputs, i.e. labels.\n",
    "\n",
    "![X_train is training input data, y_train is training output data](training_data.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()\n",
    "\n",
    "print(\"X_train_raw shape:\", X_train_raw.shape)\n",
    "print(\"y_train_raw shape:\", y_train_raw.shape)\n",
    "print(\"X_test_raw shape:\", X_test_raw.shape)\n",
    "print(\"y_test_raw shape:\", y_test_raw.shape)\n",
    "\n",
    "# Some useful constans\n",
    "NUM_TRAINING_SAMPLES = X_train_raw.shape[0]\n",
    "IMAGE_WIDTH = X_train_raw.shape[1]\n",
    "IMAGE_HEIGHT = X_train_raw.shape[2]\n",
    "NUM_PIXELS_PER_IMAGE = IMAGE_WIDTH * IMAGE_HEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions for printing sample digits\n",
    "\n",
    "These functions are useful for visualizing training data. We'll use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_labeled_image(image, digit, **kwargs):\n",
    "    title_options = {'fontsize': 16, 'fontweight': 'bold', 'verticalalignment': 'bottom'}\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray'), **kwargs)\n",
    "    plt.title('Sample - ' + str(digit) + ':', title_options, 'left')\n",
    "\n",
    "def print_samples(images, digits, number_of_samples, offset = 0, **kwargs):\n",
    "    number_of_columns = 2\n",
    "    number_of_rows = math.ceil(number_of_samples / 2)\n",
    "    plt.figure(figsize = (number_of_columns * 4, number_of_rows * 4))\n",
    "    for i in range(number_of_samples):\n",
    "        sample_index = offset + i\n",
    "        plt.subplot(number_of_rows, number_of_columns, i + 1)\n",
    "        print_labeled_image(images[sample_index], digits[sample_index], **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "def print_flattened_samples(flattened_images, digits, number_of_samples, offset = 0):\n",
    "    number_of_columns = 1\n",
    "    number_of_rows = number_of_samples\n",
    "    plt.figure(figsize = (number_of_columns * 10, number_of_rows * 1.5))\n",
    "    for i in range(number_of_samples):\n",
    "        plt.subplot(number_of_rows, number_of_columns, i + 1)\n",
    "        print_labeled_image([flattened_images[offset + i]], digits[offset + i], extent=(0, 784, 0, 50), aspect='equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data\n",
    "\n",
    "Let's first have a look at the input and output data in its raw shape. We print some samples just to show what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_samples(X_train_raw, y_train_raw, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Input Data (X)\n",
    "\n",
    "We convert each image to a vector of length 784, each value representing the \"whiteness\" of a pixel. This is necessary for feeding the data into the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "X_train_flattened = X_train_raw.reshape(X_train_raw.shape[0], NUM_PIXELS_PER_IMAGE).astype('float32')\n",
    "X_test_flattened = X_test_raw.reshape(X_test_raw.shape[0], NUM_PIXELS_PER_IMAGE).astype('float32')\n",
    "print(\"X_train_flattened shape: \", X_train_flattened.shape)\n",
    "print(\"X_test shape: \", X_test_flattened.shape)\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train_flattened / 255\n",
    "X_test = X_test_flattened / 255\n",
    "\n",
    "print_flattened_samples(X_train, y_train_raw, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Output Data (y)\n",
    "\n",
    "The output (y) data also needs to be converted. The output of our neural network will be a vector of length 10, each value representing the propability of the input sample being an image of that digit. \n",
    "\n",
    "To make it easier to compare that output to the actual y values, we convert the output into vectors representing a 100% probability that the sample is an image of that digit.\n",
    "\n",
    "__Example:__ The output value __7__ is converted into a vector __[0, 0, 0, 0, 0, 0, 0, 1, 0 , 0]__\n",
    "\n",
    "This is also known as _one hot encoding_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_raw)\n",
    "y_test = np_utils.to_categorical(y_test_raw)\n",
    "\n",
    "NUM_CLASSES = y_test.shape[1]\n",
    "\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"Example output transformation : %d => %s\" % (y_train_raw[0], str(y_train[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training a Neural Network\n",
    "\n",
    "Finally we get to the fun part: The neural networking! We'll rely heavily on the Keras library which makes it very simple to create and train the model.\n",
    "\n",
    "First we define a function that creates a neural network architecture with one hidden layer and initializes its weights to random numbers. NUMBER_OF_PIXELS_PER_IMAGE is 784 = 28x28. NUM_CLASSES is 10, one for each number from 0 to 9. The network architecture looks like this:\n",
    "\n",
    "![Neural network architecture](network.jpg)\n",
    "\n",
    "Then we build the model and specify what optimization algorithm and cost function we'd like to use when training. The resulting training setup looks like this:\n",
    "\n",
    "![Model training setup](model.jpg)\n",
    "\n",
    "We will reuse this model initialization later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # define architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(NUM_PIXELS_PER_IMAGE, input_dim=NUM_PIXELS_PER_IMAGE, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, kernel_initializer='normal', activation='softmax'))\n",
    "    # Build model with a cost function (loss) and an optimizer.\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains a given model with given training data and prints the result. The training data is divided into batches of 200 samples each and we train the model on them until all samples have been seen 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "    # Final evaluation of the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally: We create an untrained model, then train it. Once this is done, it should be able to reasonably recognize hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "train_model(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Trained Model\n",
    "\n",
    "We start with a utility function to read an image file, assumed to be a 28x28 black-and-white .png image containing one hand-written digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_digit(filename):\n",
    "    fromfile = img.imread(filename)\n",
    "    grayscale_image = fromfile[:,:,0] # Reduced to grayscale from RGB\n",
    "    plt.imshow(grayscale_image, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "    return grayscale_image.reshape(784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a function to manually test the model with a handwritten digit of your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_image(model, filename):\n",
    "    test_digit = read_digit(filename)\n",
    "    # let the model predict what digit this is and visualize the result\n",
    "    predicted = model.predict(numpy.array([test_digit]), 1)\n",
    "    plt.bar([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], predicted[0], align='center')\n",
    "    plt.show()\n",
    "    print(\"Most likely:\", numpy.argmax(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we use the evaluation function to test the model. Try it with a few samples of your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_image(model, \"../drawingboard/digit.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Excercise\n",
    "\n",
    "### Your task: train a new model to recognize sevens with a horizontal bar.\n",
    "\n",
    "#### Hints:\n",
    "1. You need to add training data containing sevens with horizontal bars, both input (X_train) and output (y_train)\n",
    "2. There are 5 files containing handwritten sevens in \"../sevens/digit{1-5}.png\"\n",
    "\n",
    "#### Some useful functions:\n",
    "\n",
    "`[ expr(i) for i in range(MAX)]` <-- creates a list with MAX elements, values expr(i) from 0 to MAX, i.e.\n",
    "\n",
    "`[ i*i for i in range(4)]` => `[0, 1, 4, 9]`\n",
    "\n",
    "`[1, 2, 3].append(4)` => `[1, 2, 3, 4]`\n",
    "\n",
    "`numpy.append(numpy.create([[1, 2],[3, 4]]), [5, 6])` => `numpy.array([[1, 2], [3, 4], [5, 6]])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function might be useful\n",
    "def read_seven(sequence_number):\n",
    "    return read_digit(\"../sevens/digit\" + str(sequence_number) + \".png\")\n",
    "\n",
    "# extend the training data set with a large set of sevens\n",
    "# \n",
    "# ... input images\n",
    "# X_train_with_sevens = < your code here >\n",
    "#\n",
    "# ... and output digits\n",
    "# y_train_with_sevens = < your code here >\n",
    "#\n",
    "# Then initialize and train the model\n",
    "\n",
    "\n",
    "# Finally evaluate the result\n",
    "evaluate_with_image(model, \"../drawingboard/digit.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Some utilities for the curious\n",
    "\n",
    "Use `describe model()` if you're curious about the representation and current state (weights) of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_weights(layer):\n",
    "    weights = layer.get_weights()\n",
    "    input_weights = weights[0]\n",
    "    bias_vector = weights[1]\n",
    "    print(\"input weights shape:\", numpy.array(input_weights).shape)\n",
    "    print(\"bias vector shape:\", numpy.array(bias_vector).shape)\n",
    "    print(\"input weights first neuron:\", input_weights[0])\n",
    "    print(\"bias vector:\", bias_vector)\n",
    "\n",
    "    \n",
    "def describe_model(model):\n",
    "    for layer in model.layers:\n",
    "        print(\"units:\", layer.units)\n",
    "        print(\"input:\", layer.input)\n",
    "        print(\"output:\", layer.output)\n",
    "        print_weights(layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
